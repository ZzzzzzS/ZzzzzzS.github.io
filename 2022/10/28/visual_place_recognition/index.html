<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Visual Place Recognition via HMM Filter and Smoother | ZZSHUB</title><meta name="author" content="Zishun Zhou"><meta name="copyright" content="Zishun Zhou"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Visual Place Recognition via HMM Filter and Smoother Abstract—Visual position recognition affects the safety and accuracy of automatic driving. To accurately identify the location, this paper studies">
<meta property="og:type" content="article">
<meta property="og:title" content="Visual Place Recognition via HMM Filter and Smoother">
<meta property="og:url" content="https://blog.zzshub.cn/2022/10/28/visual_place_recognition/index.html">
<meta property="og:site_name" content="ZZSHUB">
<meta property="og:description" content="Visual Place Recognition via HMM Filter and Smoother Abstract—Visual position recognition affects the safety and accuracy of automatic driving. To accurately identify the location, this paper studies">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog%2FShapes.jpg">
<meta property="article:published_time" content="2022-10-27T16:00:00.000Z">
<meta property="article:modified_time" content="2024-07-02T05:07:11.688Z">
<meta property="article:author" content="Zishun Zhou">
<meta property="article:tag" content="Computer Vision">
<meta property="article:tag" content="State Estimation">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog%2FShapes.jpg"><link rel="shortcut icon" href="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/logo.ico"><link rel="canonical" href="https://blog.zzshub.cn/2022/10/28/visual_place_recognition/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//www.clarity.ms"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="blth2QTunwBDdAVeivflGOQ5yFAKkRto5hERrzSe7Zw"/><meta name="baidu-site-verification" content="J5gSYw6HO1"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?30631f1de6b7510bb2f006c33e30d765";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>(function(c,l,a,r,i,t,y){
    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
    t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
})(window, document, "clarity", "script", "n0xcwltp2w");</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体中文","cht_to_chs":"你已切换为简体中文","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Visual Place Recognition via HMM Filter and Smoother',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-07-02 13:07:11'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="ZZSHUB" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/zzslogo.jpg" onerror="onerror=null;src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">41</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时光机</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E6%B8%B8%E6%88%8F"><i class="fa-fw /games/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E5%9B%BE%E4%B9%A6"><i class="fa-fw /books/"></i><span> 2</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url('https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog%2FShapes.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="ZZSHUB"><span class="site-name">ZZSHUB</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时光机</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E6%B8%B8%E6%88%8F"><i class="fa-fw /games/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E5%9B%BE%E4%B9%A6"><i class="fa-fw /books/"></i><span> 2</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Visual Place Recognition via HMM Filter and Smoother</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-10-27T16:00:00.000Z" title="发表于 2022-10-28 00:00:00">2022-10-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-07-02T05:07:11.688Z" title="更新于 2024-07-02 13:07:11">2024-07-02</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>20分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Visual Place Recognition via HMM Filter and Smoother"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Visual-Place-Recognition-via-HMM-Filter-and-Smoother"><a href="#Visual-Place-Recognition-via-HMM-Filter-and-Smoother" class="headerlink" title="Visual Place Recognition via HMM Filter and Smoother"></a>Visual Place Recognition via HMM Filter and Smoother</h1><blockquote>
<p><strong>Abstract</strong>—Visual position recognition affects the safety and accuracy of automatic driving. To accurately identify the location, this paper studies a visual place recognition algorithm based on HMM filter and HMM smoother. Firstly, we constructed the traffic situations in Canberra city. Then the mathematical models of the HMM filter and HMM smoother were performed. Finally, the vehicle position was predicted based on the algorithms. Experiment results show that HMM smoother is better than HMM filter in terms of prediction accuracy. </p>
</blockquote>
<h1 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h1><p>Visual place recognition is a well-defined problem: given an image taken at a certain place, people, animals, computers or robots should judge whether the corresponding place of the image has been seen before; If it has been seen, where is the image taken [1]. This technique provides basic position information for automatic driving, and its accuracy directly determines the safety and accuracy of automatic driving. Therefore, the research on visual place recognition is particularly basic and important.</p>
<p>Due to the large amount of data, low latency and the limitation of the hardware in autonomous driving vison-based scenarios, it is required to develop an algorithm that can not only process the image data output by the camera sensor quickly and efficiently but also reduce the storage and computing burden for the hardware chips.  </p>
<p>For vision-based location recognition, the sophisticated local-invariant feature extractors, such as Scale-Invariant Feature Transformation and Speed-Up Robust Features, hand-crafted global image descriptors, such as Generalized Search Tress, and the bag-of-visual-words approach were widely used [2]. Recent years, with the development of the deep learning, the convolution neural network is a widely used technique. It offers state-of-the-art performance on many category-level recognition tasks, such as object classification, scene recognition, and image classification.  </p>
<p>However, all the techniques above required not only high-performance computing of the hardware but also a huge storage of the memory. It needs to store all the past picture data and compare it with the sensor’s current measurements, which will highly increase the cost of the autonomous vehicle.</p>
<p>Markov chain has the characteristics of the current state only depends on the previous state, fast computation, easy deployment and does not require too high performance. Hidden Markov Chains only require the measurements of each current state. This feature can significantly improve the speed of the recognition and highly reduce the amount of data to be processed and stored for the place recognition. In this paper, we proposed two methods based on Hidden Markov Chains.</p>
<p>Filtering is the problem if estimating the current state at this time given the history of the sensor (camera) measurements. Hidden Markov filter obtains the estimated current state based on the past measurements, while hidden Markov Smoother obtains the estimated state based on the measurements before and after it, which are forward pass and backward pass. It is the problem of estimating the state at this time given past, present and future sensor measurements. The key point in the algorithms above is to obtain a reasonable transmission matrix that can compute to estimate the current state of the autonomous driving vehicle. On the basis of the filter, the smoother introduces more state data, which will improve the accuracy of location recognition.</p>
<p>Thus, in this paper, the filter and smoother of Hidden Markov Chains were used in place recognition. It is expected that the algorithms can avoid the hardware performance requirements while maintaining high accuracy. It can improve computing speed and simplify the complexity of location recognition algorithms. This paper is organized as follows. In section 1, we introduced the topic of this paper, system modeling and problem statement is in section 2, the proposed algorithm is described in section 3, detailed simulation result is shown in section 4 and in section 5 summarize this paper.</p>
<h1 id="SYSTEM-MODELING"><a href="#SYSTEM-MODELING" class="headerlink" title="SYSTEM MODELING"></a>SYSTEM MODELING</h1><p>As mentioned above, this paper mainly discusses the problem of re-localization in autonomous driving systems. Different from existing hierarchical clustering-based bag-of-words methods, this paper introduces a directed graph-based Hidden Markov Model. Combined with observation it can relocate vehicle positions. This paper uses a Hidden Markov Model based filter to solve the location. In addition, this paper also uses HMM based smoother to verify the results.</p>
<h2 id="map-prior-probability"><a href="#map-prior-probability" class="headerlink" title="map prior probability"></a>map prior probability</h2><p>In order to describe the actual position of the vehicle in the map, we establish a position set $V&#x3D;{p_1,p_2,\ldots p_i,\ldots,p_M}$. Where $p_i\in V$ represents a certain position in the map. Let $E_{ij}$ represent the connection from the $p_i$ to the $p_j$ , where $i,j \in M$. Let $\Phi_{ij}$ represent the transition probability from position $p_i$ to position $p_j$, that is, the probability that the next status is $p_j$ when the current position is $p_i$, which also can be represented as $P\left(p_j\middle| p_i\right)$. Since $\Phi_{ij}$ is expressed as probability, the sum of transition probabilities should be one.</p>
<p>$$<br>\sum_{j}^{j\in s}\Phi_{i,j}&#x3D;1<br>$$</p>
<p>where <em>s</em> is the position directly connected to the current position. Since the transition probability is position dependent, $E_{ij}\neq E_{ji}$, which is $P\left(p_j\middle| p_i\right)\neq P\left(p_i\middle| p_j\right)$. From this we can build a directed graph.</p>
<p>$$<br>G\left(V,E,\Phi\right)<br>$$</p>
<p>In the graph, $V, E, \Phi$ represent the vertex, edge, and edge weight, respectively, and the specific definitions are as above. As shown in the figure below, this project uses the Canberra city center map as the system map then simulates the status by combining the actual traffic flow data. The red vertex in the figure represents the position $p_i$ in the model, and the blue edge represents that the position $p_i$ is directly connected to $p_j$, that is, $P\left(p_j\middle| p_i\right)\neq0$. We establish different transition probabilities $\Phi_{ij}$ for different edges according to the traffic flow. At vertex such as 1 to 9 on the main road, there will be a higher probability of going straight and a lower probability of stopping. Take node 1 as an example,  $\Phi_{1,2}&gt;\Phi_{1,70}&gt;\Phi_{1,1}$. For nodes that are not on the main road, such as node 66, the probability of driving in each direction is roughly the same, and there is also a certain probability of parking. The full transition probability table designed in this paper is attached in the appendix.</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/visual_place_recog/image1.png"></p>
<center>Fig.1 The connection between positions in the simulated system.</center>

<h2 id="vehicle-position-measurement"><a href="#vehicle-position-measurement" class="headerlink" title="vehicle position measurement"></a>vehicle position measurement</h2><p>Let the observation result of the vehicle at a certain position $x$ be $y_x$, where $y,x \in V$. The vehicle may have different observations at this location, and the probability of observing different positions can be expressed as the following probability. $P\left(y&#x3D;p_j\middle| x&#x3D;p_i\right)$, where $\sum_{p_j}^{p_j\in V}{P\left(y&#x3D;p_j\middle| x&#x3D;p_i\right)}&#x3D;1.$</p>
<p>This project uses designed discrete observation probabilities then add Gaussian noise to simulate real observations. Let the preset discrete observation probability be $P_c$, and the superimposed Gaussian noise be $P_{gaussian}$. </p>
<p>In this project, different observation probabilities are designed according to different road conditions. Among them, the probability between the nodes directly connected to the node is not 0, and the observation probability of the node cannot directly connect to the current node is 0. Since this project believes that the sensor itself has high measurement accuracy, the probability of correct observation is much greater than the probability of incorrect observation, namely.</p>
<p>$$<br>P\left(y&#x3D;p_i\middle| x&#x3D;p_i\right)\gg P\left(y\neq p_i\middle| x&#x3D;p_i\right)<br>$$</p>
<p>On average $P\left(y&#x3D;p_i\middle| x&#x3D;p_i\right)\approx0.7$. The final observation probability of the vehicle still needs to add Gaussian noise on the basis of the discrete probability described above to simulate the noise situation in the observation, then normalize it so that the probability sum is 1. The Gaussian noise superimposed in this project is $\mu&#x3D;p_i,\delta&#x3D;1$. The final observation probability is as follows:<br>$$<br>P\left(y&#x3D;p_j\middle| x&#x3D;p_i\right)<br>$$</p>
<p>$$<br>&#x3D;\left(P_c\left(y&#x3D;p_j\middle| x&#x3D;p_i\right)+P_{gaussian}\left(p_j;p_i\right)\right)\times\delta<br>$$</p>
<p>$$<br>P_{gaussian}\left(p_j;p_i\right)&#x3D;\frac{1}{\sqrt{2\pi}}exp{\left(-\frac{\left(p_j-p_i\right)^2}{2}\right)}<br>$$</p>
<p>where $\delta$ is the normalization coefficient. </p>
<p>$$<br>\delta&#x3D;1+\sum_{p_j}^{p_j\in V}{P_{gaussian}\left(p_j;p_i\right)}<br>$$</p>
<h1 id="PROPOSED-INFERENCE-ALGORITHM"><a href="#PROPOSED-INFERENCE-ALGORITHM" class="headerlink" title="PROPOSED INFERENCE ALGORITHM"></a>PROPOSED INFERENCE ALGORITHM</h1><p>HMM is an unobservable motion sequence randomly generated by a hidden Markov chain. We use HMM filter and HMM smoother for visual place recognition. In this way, we could use time sequence of the images and the high relationship between the time and position due to the limited movement [3]. The mathematical details of HMM filter and HMM smoother are shown below.</p>
<h2 id="HMM-filter"><a href="#HMM-filter" class="headerlink" title="HMM filter"></a>HMM filter</h2><p>he vector ${\hat{X}}_k\in R^n$ is defined as the filter estimate, which represents the conditional probability mass function of $X_k$ given $y_1,y_2,\ldots,y_k$:<br>$$<br>{\hat{X}}_k&#x3D;\left[\begin{matrix}p\left(X_k&#x3D;1\middle| y_1,y_2,\ldots,y_k\right)\<br> p\left(X_k&#x3D;2\middle| y_1,y_2,\ldots,y_k\right)\<br>  \vdots\<br>   p\left(X_k&#x3D;n\middle| y_1,y_2,\ldots,y_k\right)\<br>   \end{matrix} \right]<br>$$</p>
<p>The matrix $A\in R^{n\times n}$ is defined as the transition probability matrix:</p>
<p>$$<br>A&#x3D;\left[\begin{matrix}p\left(X_k&#x3D;1\middle| X_{k-1}&#x3D;1\right)&amp;\cdots&amp;p\left(X_k&#x3D;1\middle| X_{k-1}&#x3D;n\right)\ \vdots&amp;\ddots&amp;\vdots\ p\left(X_k&#x3D;n\middle| X_{k-1}&#x3D;1\right)&amp;\cdots&amp;p\left(X_k&#x3D;n\middle| X_{k-1}&#x3D;n\right)\ \end{matrix}\right]<br>$$<br>Diagonal matrix $B(y_k)\in R^{n\times n}$ is defined with likelihoods for measurement $y_k$ on its diagonal:</p>
<p>$$<br>B\left(y_k\right)&#x3D;\left[\begin{matrix}p\left(y_k\middle| X_{k-1}&#x3D;1\right)&amp;\cdots&amp;0\ \vdots&amp;\ddots&amp;\vdots\ 0&amp;\cdots&amp;p\left(y_k\middle| X_{k-1}&#x3D;n\right)\ \end{matrix}\right]<br>$$</p>
<p>Then we could written the HMM filter as follows:</p>
<p>$$<br>{\hat{X}}_k&#x3D;N_k^{-1}B\left(y_k\right) A{\hat{X}} _{k-1}<br>$$</p>
<p>where $A{\hat{X}}_{k-1}$ represents the “prediction step”,  $N_k^{-1}B\left(y_k\right)$ represents the “update step”, and $N_k\in R$ normalizes to ensure ${\hat{X}}_k$ is a probability mass function, i.e., </p>
<p>$$<br>N_k&#x3D;\sum_{i&#x3D;1}^{n}{V(i)} with  V&#x3D;B(y_k)A{\hat{X}}_{k-1}<br>$$</p>
<h2 id="HMM-smoother"><a href="#HMM-smoother" class="headerlink" title="HMM smoother"></a>HMM smoother</h2><p>The first step for HMM smoother called Forward Pass. In this step, we have to calculate the unnormalized filter estimate. The details are as follows.</p>
<ul>
<li>The vector is defined as the unnormalized filter estimate:</li>
</ul>
<p>$$<br>\alpha_k&#x3D;\left[\begin{matrix}p\left(X_k&#x3D;1,y_1,y_2,\ldots,y_k\right)\ p\left(X_k&#x3D;2,y_1,y_2,\ldots,y_k\right)\ \vdots\ p\left(X_k&#x3D;n,y_1,y_2,\ldots,y_k\right)\ \end{matrix}\right]<br>$$</p>
<ul>
<li>When k change from 1 to T, compute the unnormalized filter estimate:<br>$$<br>\alpha_k&#x3D;B\left(y_k\right)A\alpha_{k-1}<br>$$</li>
</ul>
<p>with$\alpha_0&#x3D;\pi_0$</p>
<p>The second step called Backward Pass. In this step, we have to calculate the unnormalized backward filter estimate. The details are as follows.</p>
<ul>
<li><p>The vector $\beta_k\in R^n$ is defined as the unnormalized backward filter estimate:<br>$$<br>\beta_k&#x3D;\left[\begin{matrix}p\left(X_k&#x3D;1,y_{k+1},y_{k+2},\ldots,y_T\right)\ p\left(X_k&#x3D;2,y_{k+1},y_{k+2},\ldots,y_T\right)\ \vdots\ p\left(X_k&#x3D;n,y_{k+1},y_{k+2},\ldots,y_T\right)\ \end{matrix}\right]<br>$$</p>
</li>
<li><p>When k change from T to 1, compute the unnormalized backward filter estimate:<br>$$<br>\beta_{k-1}&#x3D;A^\prime B\left(y_k\right)\beta_k<br>$$</p>
</li>
</ul>
<p>where $\beta_T&#x3D;1$ representing the vector of ones, and $ A^\prime$ represents the transpose of A.</p>
<p>The final step called Multiply and Normalize. In this step, we have to calculate the smoother estimate, which represents the final result. The details are as follows.</p>
<ul>
<li><p>The vector $ \gamma_k\in R^n$ is defined as the smoother estimate:<br>$$<br>\gamma_k&#x3D;\left[\begin{matrix}p\left(X_k&#x3D;1\middle| y_1,y_2,\ldots,y_T\right)\ p\left(X_k&#x3D;2\middle| y_1,y_2,\ldots,y_T\right)\ \vdots\ p\left(X_k&#x3D;n\middle| y_1,y_2,\ldots,y_T\right)\ \end{matrix}\right]<br>$$</p>
</li>
<li><p>When k change from 0 to T, computer and normalize via elementwise multiplication:<br>$$\gamma_k\left(x_k\right)&#x3D;\frac{\alpha_k\left(x_k\right)\beta_k\left(x_k\right)}{\sum{\alpha_k\left(x_k\right)\beta_k\left(x_k\right)}}$$</p>
</li>
</ul>
<h1 id="Simulation-Results"><a href="#Simulation-Results" class="headerlink" title="Simulation Results"></a>Simulation Results</h1><p>We selected 105 traffic intersections in Canberra central, and found the current location of cars through HMM filter and HMM smoother model. To make comparison, we set the length of the state sequence to be generated to 50. It was required to design an evaluation method. In this simulation, we used accuracy.</p>
<p>$$<br>accuracy&#x3D;\frac{Number\ of\ correct\ estimated\ states}{Number\ of\ all\ states}<br>$$</p>
<p>The simulation results are shown below.</p>
<h2 id="Initial-state-5"><a href="#Initial-state-5" class="headerlink" title="Initial state &#x3D; 5"></a>Initial state &#x3D; 5</h2><p>We started experiment from setting initial state as 5 and did the following experiments.</p>
<h3 id="Initial-state-5-Sigma-1"><a href="#Initial-state-5-Sigma-1" class="headerlink" title="Initial state&#x3D;5, Sigma &#x3D; 1"></a>Initial state&#x3D;5, Sigma &#x3D; 1</h3><p>Firstly, we set the covariance of Gaussian Variance as 1. The HMM filter result can be seen in the image below.</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/visual_place_recog/image3.png"></p>
<center>Fig.2 Filter simulation: Initial state=5, sigma=1</center>

<p>The accuracy of HMM filter is 0.76.</p>
<p>The result of HMM smoother can be seen in the image below.</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/visual_place_recog/image4.png"></p>
<center>Fig.3 Smoother simulation: Initial state=5, sigma=1</center>

<p>The accuracy of HMM Smoother is 0.88.</p>
<p>The image below shows the performance of filter and smoother when initial state is 5 and sigma is 1.</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/visual_place_recog/image5.png"></p>
<center>Fig.4 Comparison: Initial state=5, sigma=1</center>

<h3 id="Initial-state-5-Sigma-2"><a href="#Initial-state-5-Sigma-2" class="headerlink" title="Initial state&#x3D;5, Sigma &#x3D; 2"></a>Initial state&#x3D;5, Sigma &#x3D; 2</h3><p>When setting the covariance of Gaussian noise is 2, the result of HMM filter can be seen in the image below.</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/visual_place_recog/image6.png"></p>
<center>Fig.5 Filter simulation: Initial state=5, sigma=2</center>

<p>The accuracy of HMM filter when sigma equals 2 is 0.68.</p>
<p>The result of HMM smoother can be seen in the image below.</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/visual_place_recog/image7.png"></p>
<center>Fig.6 Smoother simulation: Initial state=5, sigma=2</center>

<p>The accuracy of HMM smoother is 0.82.</p>
<p>The image below shows the performance of filter and smoother when initial state is 5 and sigma is 2.</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/visual_place_recog/image8.png"></p>
<center>Fig.7 Comparison: Initial state=5, sigma=2</center>

<h2 id="Initial-state-90"><a href="#Initial-state-90" class="headerlink" title="Initial state &#x3D; 90"></a>Initial state &#x3D; 90</h2><p>Then we set the initial state as 90, sigma &#x3D; 1</p>
<p>Similarly, we set the covariance of Gaussian Variance as 1. The HMM filter result can be seen in the image below.</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/visual_place_recog/image9.png"></p>
<center>Fig.8 Filter simulation: Initial state=90, sigma=1</center>

<p>The accuracy of HMM filter in this assumption is 0.76.</p>
<p>The result of HMM smoother can be seen below.</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/visual_place_recog/image10.png"></p>
<center>Fig.9 Smoother simulation: Initial state=90, sigma=1</center>

<p>The accuracy of HMM smoother in this assumption is 0.82.</p>
<p>The image below shows the performance of filter and smoother when initial state is 90 and sigma is 1.</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/visual_place_recog/image11.png"></p>
<center>Fig.10 Comparison: Initial state=90, sigma=1</center>

<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>We record the accuracy in the figure above in the following table.</p>
<p>Table 1. The accuracy of HMM Filter and HMM Smoother</p>
<table>
<thead>
<tr>
<th></th>
<th><strong>HMM filter accuracy</strong></th>
<th><strong>HMM smoother accuracy</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Initial state&#x3D;5 Sigma &#x3D; 1</td>
<td>76%</td>
<td>88%</td>
</tr>
<tr>
<td>Initial state&#x3D;5 Sigma &#x3D; 2</td>
<td>68%</td>
<td>82%</td>
</tr>
<tr>
<td>Initial state&#x3D;90 Sigma &#x3D; 1</td>
<td>76%</td>
<td>82%</td>
</tr>
</tbody></table>
<p>It could be drawn the following conclusions.</p>
<p>Firstly, it can be found that at the beginning, both the filter and smoother show a good performance. Then it can be seen that the smoother validates a more accurate estimations of the state. We could see that the error between the true and estimated state of the HMM smother is less than the error of the HMM filter. Especially at the end of the states, the results of the smoother are more consistent with the real state.</p>
<p>Due to the HMM smoother considered not only the past measurements of the autonomous vehicle, but also the future states of the vehicle. In other words, through backward pass, more knowledge is considered into the model when estimating the current state, which will lead a better estimation, while the filter can only estimate the state by using the past knowledge. Thus, it is reasonable that as the time went by, the advantages of the smoother over the filter become more and more obvious.</p>
<p>However, the smoother will meet more limitations in practice. In practical scenarios, it is difficult to obtain a large number of subsequent measurements of the state to be estimated. Thus, to use the smoother in practice, it is required more sensors on the vehicle and a good fusion of the sensors.</p>
<p>Secondly, the added Gaussian noise when generated measurements have also made affects in HMM filter and HMM smoother. It could be found that the higher the variance of the noise, the worse the results of the filter and smoother.</p>
<p>Thirdly, for the states where the mismatch happened, the confusion matrix affected the HMM filter and smoother. In practice, it is the accuracy of the sensor. Due to the errors in sensors when capture the places, the algorithm cannot obtain absolutely accurate measurements as the input, which will lead mismatches in the simulations results. What’s more, Bayesian algorithm is based on possibilities. If the prior belief or likelihood are inaccurate, the result will be bound to a mismatch. For this point, the algorithm like HMM smoother that introduces more knowledge will have an even greater advantage. Especially in the use of autonomous driving which requires extreme security and reliability, HMM smoother will be a better choice.</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>In this paper, HMM filter and HMM smoother were used for visual position recognition. By comparing the state observation results under different initial positions, we found that the HMM smoother had better performance. By comparing different gaussian noise, we found that the higher the noise variance, the worse the results of filter and smoother. Besides, after the theoretical analysis, we thought that the errorswhich led to the difference between the real states and the simulation resultsare the accuracy of the sensor. Thus, In order to improve the accuracy of position recognition, we put forward the followingconclusions:firstly, HMM smoother performs a better performance with more limitations.Secondly, the sensors which used to do measurements played an important role in predictions. Improving the performance of the sensors will be an essential solution if the prediction algorithmdoesn’t work well.</p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol>
<li>S. Lowry, N. Sunderhauf, P. Newman, J. J. Leonard, D. Cox, P. Corke, and M. J. Milford, “Visual place recognition: A survey,” IEEE Transactions on Robotics, vol. 32, no. 1, pp. 1–19, 2016.</li>
<li>Z. Zeng, J. Zhang, X. Wang, Y. Chen, and C. Zhu, “Place recognition: An overview of Vision Perspective,” Applied Sciences, vol. 8, no. 11, p. 2257, 2018.</li>
<li>D. Doan, Y. Latif, T.-J. Chin, Y. Liu, T.-T. Do, and I. Reid, “Scalable place recognition under appearance change for autonomous driving,” 2019 IEEE&#x2F;CVF International Conference on Computer Vision (ICCV), 2019.</li>
</ol>
<h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><h2 id="A-The-transition-probability-table"><a href="#A-The-transition-probability-table" class="headerlink" title="A.The transition probability table"></a>A.The transition probability table</h2><p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/visual_place_recog/image12.png"></p>
<p><strong>Figure</strong>  <strong>A.</strong> the full transition matrix, since the matrix has 105 cols and 105 rows, it can only be presented as a figure. This figure has 105x105 pixels, each pixel represents one of the elements in the matrix. The brightness of pixels represents the probability of that element. The lighter pixel will have a larger probability. The sum of each cols are equal to one.</p>
<h2 id="B-The-observation-matrix"><a href="#B-The-observation-matrix" class="headerlink" title="B.The observation matrix"></a>B.The observation matrix</h2><p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/visual_place_recog/image13.png"></p>
<p><strong>Figure B</strong> The full observation matrix. This is a 105x105 figure, where each pixel represents one of the elements in observation matrix, the definition of brightness is the same as transition matrix figure. The average value of diagonal elements is 0.7.</p>
<h1 id="PDF-Version-Download"><a href="#PDF-Version-Download" class="headerlink" title="PDF Version Download"></a>PDF Version Download</h1><p>The PDF version of this article can be downloaded from the following link:</p>
<p><a target="_blank" rel="noopener" href="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/visual_place_recog/Report.pdf">Download Here</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.zzshub.cn">Zishun Zhou</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.zzshub.cn/2022/10/28/visual_place_recognition/">https://blog.zzshub.cn/2022/10/28/visual_place_recognition/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.zzshub.cn" target="_blank">ZZSHUB</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Computer-Vision/">Computer Vision</a><a class="post-meta__tags" href="/tags/State-Estimation/">State Estimation</a></div><div class="post_share"><div class="social-share" data-image="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog%2FShapes.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/wechatpay.JPG" target="_blank"><img class="post-qr-code-img" src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/wechatpay.JPG" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/11/13/360VO_Research/" title="Research Report of 360VO Visual Odometry Using A Single 360 Camera"><img class="cover" src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog%2FShapes.jpg" onerror="onerror=null;src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Research Report of 360VO Visual Odometry Using A Single 360 Camera</div></div></a></div><div class="next-post pull-right"><a href="/2022/10/13/EasyMVS/" title="EasyMVS -- A Simple Multi-View Stereo lib"><img class="cover" src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog%2FShapes.jpg" onerror="onerror=null;src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">EasyMVS -- A Simple Multi-View Stereo lib</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/11/13/360VO_Research/" title="Research Report of 360VO Visual Odometry Using A Single 360 Camera"><img class="cover" src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog%2FShapes.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-13</div><div class="title">Research Report of 360VO Visual Odometry Using A Single 360 Camera</div></div></a></div><div><a href="/2022/10/13/EasyMVS/" title="EasyMVS -- A Simple Multi-View Stereo lib"><img class="cover" src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog%2FShapes.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-13</div><div class="title">EasyMVS -- A Simple Multi-View Stereo lib</div></div></a></div><div><a href="/2023/05/20/Image_Segmentation_via_Spectral_Clustering/" title="Image Segmentation via Spectral Clustering"><img class="cover" src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog%2FShapes.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-20</div><div class="title">Image Segmentation via Spectral Clustering</div></div></a></div><div><a href="/2023/03/24/JacobiBasedPTZControl/" title="基于图像雅可比的目标跟踪控制"><img class="cover" src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/JacobiPTZControl/Picture1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-24</div><div class="title">基于图像雅可比的目标跟踪控制</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/zzslogo.jpg" onerror="this.onerror=null;this.src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.gif'" alt="avatar"/></div><div class="author-info__name">Zishun Zhou</div><div class="author-info__description">周子顺</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">41</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ZzzzzzS"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ZzzzzzS" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:zhouzishun@mail.zzshub.cn" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fas fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">这个人很懒，他什么也没留下</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Visual-Place-Recognition-via-HMM-Filter-and-Smoother"><span class="toc-number">1.</span> <span class="toc-text">Visual Place Recognition via HMM Filter and Smoother</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#INTRODUCTION"><span class="toc-number">2.</span> <span class="toc-text">INTRODUCTION</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SYSTEM-MODELING"><span class="toc-number">3.</span> <span class="toc-text">SYSTEM MODELING</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#map-prior-probability"><span class="toc-number">3.1.</span> <span class="toc-text">map prior probability</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#vehicle-position-measurement"><span class="toc-number">3.2.</span> <span class="toc-text">vehicle position measurement</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#PROPOSED-INFERENCE-ALGORITHM"><span class="toc-number">4.</span> <span class="toc-text">PROPOSED INFERENCE ALGORITHM</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HMM-filter"><span class="toc-number">4.1.</span> <span class="toc-text">HMM filter</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HMM-smoother"><span class="toc-number">4.2.</span> <span class="toc-text">HMM smoother</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Simulation-Results"><span class="toc-number">5.</span> <span class="toc-text">Simulation Results</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Initial-state-5"><span class="toc-number">5.1.</span> <span class="toc-text">Initial state &#x3D; 5</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Initial-state-5-Sigma-1"><span class="toc-number">5.1.1.</span> <span class="toc-text">Initial state&#x3D;5, Sigma &#x3D; 1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Initial-state-5-Sigma-2"><span class="toc-number">5.1.2.</span> <span class="toc-text">Initial state&#x3D;5, Sigma &#x3D; 2</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Initial-state-90"><span class="toc-number">5.2.</span> <span class="toc-text">Initial state &#x3D; 90</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Summary"><span class="toc-number">5.3.</span> <span class="toc-text">Summary</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Conclusion"><span class="toc-number">6.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#References"><span class="toc-number">7.</span> <span class="toc-text">References</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Appendix"><span class="toc-number">8.</span> <span class="toc-text">Appendix</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#A-The-transition-probability-table"><span class="toc-number">8.1.</span> <span class="toc-text">A.The transition probability table</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#B-The-observation-matrix"><span class="toc-number">8.2.</span> <span class="toc-text">B.The observation matrix</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#PDF-Version-Download"><span class="toc-number">9.</span> <span class="toc-text">PDF Version Download</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/06/21/DRL_LeggedgymInstall/" title="强化学习仿真器Isaac Gym的安装，配置，与初步使用"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_installIsaacgym/cover.png" onerror="this.onerror=null;this.src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.jpg'" alt="强化学习仿真器Isaac Gym的安装，配置，与初步使用"/></a><div class="content"><a class="title" href="/2024/06/21/DRL_LeggedgymInstall/" title="强化学习仿真器Isaac Gym的安装，配置，与初步使用">强化学习仿真器Isaac Gym的安装，配置，与初步使用</a><time datetime="2024-06-21T04:00:00.000Z" title="发表于 2024-06-21 12:00:00">2024-06-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/21/start_rl/" title="机器人控制中的强化学习极简入门指南"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/start_rl/cover.jpg" onerror="this.onerror=null;this.src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.jpg'" alt="机器人控制中的强化学习极简入门指南"/></a><div class="content"><a class="title" href="/2024/05/21/start_rl/" title="机器人控制中的强化学习极简入门指南">机器人控制中的强化学习极简入门指南</a><time datetime="2024-05-21T04:00:00.000Z" title="发表于 2024-05-21 12:00:00">2024-05-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/08/30/wslgperformace/" title="WSL中的GPU原理总结"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/wslgpuperformance/logo.png" onerror="this.onerror=null;this.src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.jpg'" alt="WSL中的GPU原理总结"/></a><div class="content"><a class="title" href="/2023/08/30/wslgperformace/" title="WSL中的GPU原理总结">WSL中的GPU原理总结</a><time datetime="2023-08-30T06:12:32.000Z" title="发表于 2023-08-30 14:12:32">2023-08-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/26/DRL_RaisimGymTorch/" title="强化学习仿真器Raisim进行深度强化学习的初步尝试"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/RaisimInstall/logo.png" onerror="this.onerror=null;this.src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.jpg'" alt="强化学习仿真器Raisim进行深度强化学习的初步尝试"/></a><div class="content"><a class="title" href="/2023/07/26/DRL_RaisimGymTorch/" title="强化学习仿真器Raisim进行深度强化学习的初步尝试">强化学习仿真器Raisim进行深度强化学习的初步尝试</a><time datetime="2023-07-26T08:12:32.000Z" title="发表于 2023-07-26 16:12:32">2023-07-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/26/DRL_RaisimInstall/" title="强化学习仿真器Raisim的安装，配置，与初步使用"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/RaisimInstall/logo.png" onerror="this.onerror=null;this.src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.jpg'" alt="强化学习仿真器Raisim的安装，配置，与初步使用"/></a><div class="content"><a class="title" href="/2023/07/26/DRL_RaisimInstall/" title="强化学习仿真器Raisim的安装，配置，与初步使用">强化学习仿真器Raisim的安装，配置，与初步使用</a><time datetime="2023-07-26T06:12:32.000Z" title="发表于 2023-07-26 14:12:32">2023-07-26</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2017 - 2024 By Zishun Zhou</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">喵喵喵喵喵</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/utils.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/main.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/tw_cn.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const initGitalk = () => {
    const gitalk = new Gitalk(Object.assign({
      clientID: 'Ov23li0kkKyhMGCSCF8C',
      clientSecret: 'e6803156ae2eb0273961046aaa938b39152eb81a',
      repo: 'ZzzzzzS.github.io',
      owner: 'ZzzzzzS',
      admin: ['ZzzzzzS'],
      id: '11ee7bb8d788981bba36ad496eccbee6',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async() => {
    if (typeof Gitalk === 'function') initGitalk()
    else {
      await getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk()
    }
  }
  
  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/search/local-search.min.js"></script></div></div><script src="https://cdn.jsdelivr.net/npm/live2d-widget@^3.1.3/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"https://cdn.jsdelivr.net/npm/live2d-widget-model-shizuku/assets/shizuku.model.json"},"display":{"position":"left","hOffset":60,"vOffset":0,"width":150,"height":300},"mobile":{"show":false},"react":{"opacity":1},"dialog":{"enable":true,"hitokoto":true},"log":false});</script></body></html>