<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆 | ZZSHUB</title><meta name="author" content="Zishun Zhou"><meta name="copyright" content="Zishun Zhou"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆 本篇教程将大致介绍Legged Gym的结构，使用方法，并以一个二阶倒立摆为例来完成一次实际的强化学习训练  回顾强化学习基本概念 —– 五元组 本章节将简要回顾强化学习中五元组的概念，需要读者对强化学习有基本的概念。若对强化学习缺少基本认知，建议先阅读OpenAI推出的Spinning up系列教程。读者也可先大致阅读后续章节">
<meta property="og:type" content="article">
<meta property="og:title" content="强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆">
<meta property="og:url" content="https://blog.zzshub.cn/2024/06/25/DRL_LeggedgymCartpole2/index.html">
<meta property="og:site_name" content="ZZSHUB">
<meta property="og:description" content="强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆 本篇教程将大致介绍Legged Gym的结构，使用方法，并以一个二阶倒立摆为例来完成一次实际的强化学习训练  回顾强化学习基本概念 —– 五元组 本章节将简要回顾强化学习中五元组的概念，需要读者对强化学习有基本的概念。若对强化学习缺少基本认知，建议先阅读OpenAI推出的Spinning up系列教程。读者也可先大致阅读后续章节">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_cartpole2/cover.jpg">
<meta property="article:published_time" content="2024-06-25T04:00:00.000Z">
<meta property="article:modified_time" content="2024-07-01T01:57:05.578Z">
<meta property="article:author" content="Zishun Zhou">
<meta property="article:tag" content="强化学习">
<meta property="article:tag" content="机器人">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_cartpole2/cover.jpg"><link rel="shortcut icon" href="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/logo.ico"><link rel="canonical" href="https://blog.zzshub.cn/2024/06/25/DRL_LeggedgymCartpole2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//www.clarity.ms"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="blth2QTunwBDdAVeivflGOQ5yFAKkRto5hERrzSe7Zw"/><meta name="baidu-site-verification" content="J5gSYw6HO1"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?30631f1de6b7510bb2f006c33e30d765";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>(function(c,l,a,r,i,t,y){
    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
    t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
})(window, document, "clarity", "script", "n0xcwltp2w");</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体中文","cht_to_chs":"你已切换为简体中文","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-07-01 09:57:05'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="ZZSHUB" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/zzslogo.jpg" onerror="onerror=null;src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">42</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时光机</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E6%B8%B8%E6%88%8F"><i class="fa-fw /games/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E5%9B%BE%E4%B9%A6"><i class="fa-fw /books/"></i><span> 2</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url('https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_cartpole2/cover.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="ZZSHUB"><span class="site-name">ZZSHUB</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时光机</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E6%B8%B8%E6%88%8F"><i class="fa-fw /games/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E5%9B%BE%E4%B9%A6"><i class="fa-fw /books/"></i><span> 2</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-06-25T04:00:00.000Z" title="发表于 2024-06-25 12:00:00">2024-06-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-07-01T01:57:05.578Z" title="更新于 2024-07-01 09:57:05">2024-07-01</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>21分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="强化学习仿真环境Legged-Gym的初步使用——训练一个二阶倒立摆"><a href="#强化学习仿真环境Legged-Gym的初步使用——训练一个二阶倒立摆" class="headerlink" title="强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆"></a>强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆</h1><blockquote>
<p>本篇教程将大致介绍Legged Gym的结构，使用方法，并以一个二阶倒立摆为例来完成一次实际的强化学习训练</p>
</blockquote>
<h1 id="回顾强化学习基本概念-—–-五元组"><a href="#回顾强化学习基本概念-—–-五元组" class="headerlink" title="回顾强化学习基本概念 —– 五元组"></a>回顾强化学习基本概念 —– 五元组</h1><blockquote>
<p>本章节将简要回顾强化学习中五元组的概念，需要读者对强化学习有基本的概念。若对强化学习缺少基本认知，建议先阅读OpenAI推出的<a target="_blank" rel="noopener" href="https://spinningup.openai.com/en/latest/">Spinning up</a>系列教程。读者也可先大致阅读后续章节，对Legged Gym训练框架有初步认知。</p>
</blockquote>
<p>首先我们回顾一下强化学习基本概念之一的五元组，即$M&#x3D;&lt;S,A,P,R,\gamma&gt;$, 其中$S$表示状态集；$A$表示动作集 $P$ 表示状态和动作的条件转移概率，$R$ 奖励函数，最后$\gamma$表示回报率。<br>以下是这五元组的详细解释：</p>
<p><strong>状态集（$S$）：</strong></p>
<p>定义：状态集S是所有可能的状态的集合。在强化学习中，状态描述了环境当前的情况或配置。</p>
<p>特点：状态用于确定接下来会发生什么（行动、观察、奖励）。状态是关于历史的函数，即($S_t &#x3D; f(H_t)$)，其中($H_t$)是到时间$t$为止的历史信息。</p>
<p><strong>动作集（$A$）：</strong></p>
<p>定义：动作集$A$是在每个状态下所有可能的动作的集合。这些动作是智能体（Agent）可以选择执行的。</p>
<p>特点：动作是智能体与环境交互的方式，通过执行动作，智能体可以改变环境的状态。</p>
<p><strong>转移概率（$P$）：</strong><br>定义：转移概率$P$描述了从一个状态转移到另一个状态的概率分布，具体取决于当前状态和所选择的动作。</p>
<p>公式表示：($P(s’|s, a)$)表示在状态$s$执行动作$a$后转移到状态$s’$的概率。<br>特点：转移概率定义了环境的动态性，即如何从一个状态转移到另一个状态。</p>
<p><strong>奖励函数（$R$）：</strong><br>定义：奖励函数$R$是一个标量函数，用于量化智能体在给定状态下执行某个动作的好坏。</p>
<p>公式表示：($R(s, a)$)或($R(s, a, s’)$)表示在状态s执行动作$a$后（或转移到状态$s’$后）获得的即时奖励。</p>
<p>特点：奖励是强化学习的核心，它指导智能体如何学习以最大化长期累积奖励。</p>
<p><strong>折扣因子（$\gamma$）：</strong></p>
<p>定义：折扣因子$\gamma$是一个介于0和1之间的数，用于计算累积奖励时的折扣。<br>公式表示：在计算长期累积奖励时，未来的奖励会被$\gamma$折扣。例如，t时刻的累积奖励可以表示为$(G_t &#x3D; R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + \ldots)$。</p>
<p>特点：折扣因子平衡了即时奖励和未来奖励的重要性。较大的$\gamma$值使智能体更加关注长远的奖励，而较小的$\gamma$值则使其更加关注眼前的奖励。</p>
<p>我们也可以用一个框图的形式来重新表述上述五元组的概念。</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_cartpole2/rl_basic_graph.png" alt="rl_basic_graph"></p>
<p>如上图所示，我们的智能体(即我们最终训练出的神经网络$P$)在$S_t$状态下执行了$A_t$动作(即神经网络输入为$S_t$输出为$A_t$)，此时环境(即我们训练的仿真器)在接收到了$A_t$输入量后状态改变成了$S_{t+1}$，同时环境产生了$R_t$的奖励。最后计算环境产生的总汇报$G_t$时需要考虑折扣因子$\gamma$。</p>
<p>正如上图看到的那样，<strong>一个强化学习的训练框架主要可以分为训练智能体和编写环境两个部分</strong>。训练智能体包括搭建神经网络模型如MLP、LSTM、Transformer等，和设计强化学习算法如DQN、PPO、SAC等。而编写环境包括计算$S_{t+1}$状态(调用刚体动力学引擎计算机器人状态)，计算环境是否需要复位，以及最重要的编写奖励函数等。</p>
<p>对于初学者或者说对于使用强化学习应用开发来说，现有训练智能体的算法足以覆盖大部分应用场景，<strong>因此训练强化学习算法应主要集中在环境的编写上，特别是奖励函数的设计上</strong>。</p>
<p>包括Legged Gym在内的大部分强化学习框架都是将训练智能体的算法(如PPO，SAC算法)等封装起来，同时更多的保留一些方便编写环境的接口供用户使用，用户使用这个框架时更多的是在编写环境，而无需关心训练网络的细节。</p>
<h1 id="Legged-Gym-ver-ZZS-环境安装"><a href="#Legged-Gym-ver-ZZS-环境安装" class="headerlink" title="Legged Gym(ver. ZZS) 环境安装"></a>Legged Gym(ver. ZZS) 环境安装</h1><p>从<a target="_blank" rel="noopener" href="https://github.com/ZzzzzzS/legged_gym/releases">这里</a>下载最新稳定版Legger Gym(ver. ZZS)。并解压到待安装的位置(注意请妥善选择解压目录，安装后不可更改位置)。</p>
<p>在解压文件夹目录下激活<a href="">前文所述</a>安装的python3.8虚拟环境。并执行<code>pip install -e .</code>命令即可完成安装，无需再安装rsl_rl等。</p>
<p>在文件夹根目录下打开vscode，选择到左侧的<code>扩展</code>窗口，选择到最下一栏的推荐页面，并安装推荐的拓展，包括如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&quot;ms-python.python&quot;,</span><br><span class="line">&quot;ms-python.vscode-pylance&quot;,</span><br><span class="line">&quot;ms-python.pylint&quot;,</span><br><span class="line">&quot;ms-python.debugpy&quot;,</span><br><span class="line">&quot;ms-python.black-formatter&quot;,</span><br><span class="line">&quot;gruntfuggly.todo-tree&quot;</span><br></pre></td></tr></table></figure>

<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_cartpole2/vscode_extension.jpg" alt="vscode_extension"></p>
<p>到这里我们基本完成了Legged Gym(ver. ZZS)的安装，下面训练测试一下。</p>
<p>选择vscode左侧边栏中的文件浏览界面并随机打开一个以<code>.py</code>结尾的文件。之后在底部状态栏右侧选择激活前文所创建的虚拟环境，这里我命名为<code>legged-gym</code>。</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_cartpole2/vscode_train.jpg" alt="vscode_train"></p>
<p>选择vscode左侧边栏中的的调试和运行界面，在弹出的界面顶部的下拉框中有配置好的<code>train</code>和<code>play</code>两种模式。我们选择<code>train</code>模式，并单击左侧绿色小三角来开始第一次训练。若一切配置正确，可以看到在弹出的窗口中训练二阶倒立摆的场景。可以使用<code>W</code>, <code>S</code>, <code>A</code>, <code>D</code>, 和<code>shift</code>, <code>space</code>键来水平移动视角，或按住鼠标右键并拖动来旋转视角(类似于<a target="_blank" rel="noopener" href="https://www.minecraft.net/">MineCraft</a>的操作键位)。</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_cartpole2/first_train.png" alt="first_train"></p>
<h1 id="Legged-Gym-ver-ZZS-环境基本结构介绍"><a href="#Legged-Gym-ver-ZZS-环境基本结构介绍" class="headerlink" title="Legged Gym(ver. ZZS) 环境基本结构介绍"></a>Legged Gym(ver. ZZS) 环境基本结构介绍</h1><h2 id="代码文件结构梳理"><a href="#代码文件结构梳理" class="headerlink" title="代码文件结构梳理"></a>代码文件结构梳理</h2><p>整个框架的主要文件作用如下表所示。在初步使用过程中我们主要关注<code>./legged_gym/envs/</code>文件夹下的各种即可，强烈建议入门时详细阅读<code>./legged_gym/envs/base/</code>文件夹下的<code>legged_robot.py</code>和<code>legged_robot_config.py</code>，以及大致阅读<code>./scripts/</code>文件夹下<code>train.py</code>,<code>play.py</code>和<code>./vscode/</code>文件夹下的<code>launch.json</code>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">:.</span><br><span class="line">│</span><br><span class="line">├───.vscode</span><br><span class="line">│       extensions.json</span><br><span class="line">│       launch.json #启动训练相关配置</span><br><span class="line">│       settings.json #vscode其他相关配置</span><br><span class="line">│</span><br><span class="line">├───legged_gym</span><br><span class="line">│   │</span><br><span class="line">│   ├───algos       #ppo算法模块</span><br><span class="line">│   ├───envs</span><br><span class="line">│   │   ├── __init__.py #新写的环境需要在里注册</span><br><span class="line">│   │   ├───base</span><br><span class="line">│   │   │       base_config.py  #基础环境配置</span><br><span class="line">│   │   │       base_task.py    #基础环境</span><br><span class="line">│   │   │       IsaacgymAdapter.py # deprecated, no use</span><br><span class="line">│   │   │       legged_robot.py # 适用于腿足机器人的通用环境</span><br><span class="line">│   │   │       legged_robot_config.py #适用于腿足机器人的通用配置</span><br><span class="line">│   │   │</span><br><span class="line">│   │   └───cartpole2</span><br><span class="line">│   │           cartpole2.py #二阶倒立摆环境</span><br><span class="line">│   │           cartpole2_config.py #二阶倒立摆配置</span><br><span class="line">│   ├───scripts</span><br><span class="line">│   │       play.py #仿真验证训练结果的脚本</span><br><span class="line">│   │       train.py #训练网络模型的脚本</span><br><span class="line">│   │</span><br><span class="line">│   ├───tests</span><br><span class="line">│   │       test_env.py #测试新编写的环境是否可用的脚本</span><br><span class="line">│   │</span><br><span class="line">│   └───utils #一些工具集</span><br><span class="line">│           dr_utils.py #deprecated, no use</span><br><span class="line">│           ExperimentLogger.py #记录实验参数</span><br><span class="line">│           fast_dbg_viz.py #绘图工具(可用于绘制落脚点等)</span><br><span class="line">│           helpers.py #通用的各种帮助函数</span><br><span class="line">│           logger.py #ETH的logger</span><br><span class="line">│           math.py #四元数相关的计算函数</span><br><span class="line">│           rsl_utils.py #训练rnn网络的辅助工具</span><br><span class="line">│           RunningMeanStd.py #ppo算法辅助工具</span><br><span class="line">│           task_registry.py #新算法注册工具</span><br><span class="line">│           terrain.py #地形生成工具</span><br><span class="line">│           torch_jit_utils.py #四元数相关的更多函数</span><br><span class="line">│           train_batch.py #deprecated, no use</span><br><span class="line">│           Zlog.py #ZZS的logger</span><br><span class="line">│           __init__.py</span><br><span class="line">│</span><br><span class="line">└───resources #机器人的各种urdf文件和stl文件</span><br><span class="line">    └───robots</span><br><span class="line">        ├───a1</span><br><span class="line">        │   ├───meshes</span><br><span class="line">        │   └───urdf</span><br><span class="line">        ├───anymal_b</span><br><span class="line">        │   ├───meshes</span><br><span class="line">        │   └───urdf</span><br><span class="line">        ├───anymal_c</span><br><span class="line">        │   ├───meshes</span><br><span class="line">        │   └───urdf</span><br><span class="line">        ├───cartpole</span><br><span class="line">        │   ├───cartpole2.urdf #二阶倒立摆的urdf文件</span><br><span class="line">        │</span><br><span class="line">        └───cassie</span><br><span class="line">            ├───meshes</span><br><span class="line">            └───urdf</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="训练与测试"><a href="#训练与测试" class="headerlink" title="训练与测试"></a>训练与测试</h2><p>Legged Gym的训练与测试的入口程序分别是<code>./script</code>文件夹下的<code>train.py</code>和<code>play.py</code>，在python环境中运行这两个文件并附带相应参数即可完成训练或测试。为了方便用户使用和调试，这里使用了vscode的<code>launch.json</code>文件对其额外进行了一层封装来方便以图形化的方式在vscode中使用。用户可以在<code>.vscode/launch.json</code>中找到相关的定义，关于vscode中更多关于运行和调试的配置可以<a target="_blank" rel="noopener" href="https://go.microsoft.com/fwlink/?linkid=830387">点击这里</a>了解详情。</p>
<p>训练和测试支持各种参数，以下是一些常用参数和其含义，全部的参数定义参见<code>./legged_gym/utils/helpers.py</code>文件中的<code>get_args()</code>函数：</p>
<table>
<thead>
<tr>
<th>args</th>
<th>type</th>
<th>default</th>
<th>note</th>
</tr>
</thead>
<tbody><tr>
<td><code>--task</code></td>
<td><code>str</code></td>
<td>anymal_c_flat</td>
<td>指定要训练的环境名称</td>
</tr>
<tr>
<td><code>--resume</code></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>是否从上次训练的结果中继续训练</td>
</tr>
<tr>
<td><code>--load_run</code></td>
<td><code>str</code></td>
<td><code>None</code></td>
<td>上次训练的文件名(在<code>--resume True</code>时生效)</td>
</tr>
<tr>
<td><code>--checkpoint</code></td>
<td><code>int</code></td>
<td>-1</td>
<td>设置载入训练模型的迭代次数，-1表示载入最后一次迭代</td>
</tr>
<tr>
<td><code>--headless</code></td>
<td><code>bool</code></td>
<td><code>False</code></td>
<td>是否弹出渲染界面，默认弹出</td>
</tr>
<tr>
<td><code>--num_envs</code></td>
<td><code>int</code></td>
<td><code>None</code></td>
<td>指定并行训练环境的个数，不指定则使用cfg文件中的值</td>
</tr>
<tr>
<td><code>--max_iterations</code></td>
<td><code>int</code></td>
<td><code>None</code></td>
<td>训练时最大迭代次数，不指定则使用cfg文件中的值</td>
</tr>
<tr>
<td><code>--seed</code></td>
<td><code>int</code></td>
<td><code>None</code></td>
<td>设置随机种子，不指定则使用cfg文件中的值</td>
</tr>
</tbody></table>
<h2 id="环境与配置简介"><a href="#环境与配置简介" class="headerlink" title="环境与配置简介"></a>环境与配置简介</h2><p>在使用Legged Gym训练框架时我们重点关注的是<code>./env</code>环境下的内容，<code>./env</code>文件夹下的各子文件夹表示不同环境和其对应的配置文件，<code>base</code>文件夹下为最基本的环境配置。这些环境和其配置文件使用面向对象的方式编写，包含环境类如<code>./env/base/legged_robot.py</code>中的<code>LeggedRobot</code>类，环境配置类如<code>./env/base/legged_robot_config.py</code>中的<code>LeggedRobotCfg</code>类，和算法配置类如<code>./env/base/legged_robot_config.py</code>中的<code>LeggedRobotCfgPPO</code>类。其中环境类定义了不同的环境，环境配置类定义了环境中的相关参数，如奖励函数等，而算法配置类定义了强化学习算法相关的参数，如ppo的学习率等。其中所有环境的基类为<code>./env/base/base_task.py</code>中的<code>BaseTask</code>类，这个类定义了最基本的输入输出，初始化等。而所有环境配置类和算法配置类主要取决于环境和算法本身，没有太多的继承关系，不过仍需继承<code>./env/base/base_config.py</code>中的<code>BaseConfig</code>类来保证一些基本功能。</p>
<p>在Legged Gym中添加我们自己的环境主要包含定义新环境类和配置类，和注册相关类。定义新类基本就是创建一个新文件夹，拷贝<code>legged_robot_config.py</code>和<code>legged_robot.py</code>文件，修改以下环境的名称，修改以下输入输出等。下面主要讲一下如何注册相关类。打开<code>./envs/__init__.py</code>文件，在其中加入我们想要新注册的类，以及取一个我们想要的名字即可，这个名字即<code>--task name</code>参数中的<code>name</code>。<strong>注意修改算法配置类中的runner的experiment_name</strong>。</p>
<p>关于更多isaacgym仿真器的使用方法，建议大家阅读<a href="https://blog.zzshub.cn/legged_gym/">isaacgym官方tutorial和api参考手册</a>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import other environments</span></span><br><span class="line"><span class="comment"># ....</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> .cartpole2.cartpole2 <span class="keyword">import</span> Cartpole2Task</span><br><span class="line"><span class="keyword">from</span> .cartpole2.cartpole2_config <span class="keyword">import</span> Cartpole2Config, Cartpole2ConfigPPO</span><br><span class="line"></span><br><span class="line"><span class="comment"># regist other environments</span></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">task_registry.register(<span class="string">&quot;cartpole2&quot;</span>, Cartpole2Task, Cartpole2Config(), Cartpole2ConfigPPO())</span><br></pre></td></tr></table></figure>

<h1 id="强化学习实践第一步-——-二阶倒立摆训练"><a href="#强化学习实践第一步-——-二阶倒立摆训练" class="headerlink" title="强化学习实践第一步 —— 二阶倒立摆训练"></a>强化学习实践第一步 —— 二阶倒立摆训练</h1><p>上文简要介绍了Legged Gym的基本框架和使用方法，下面我将以一个二阶倒立摆为例实际介绍一个环境应该如何搭建。该环境定义在<code>./envs/cartpole2/cartpole2.py</code>中，环境相关配置文件定义在<code>./envs/cartpole2/cartpole2_config.py</code>中，所有类均需按照上文所述的方法在<code>./envs/__init__.py</code>中注册。</p>
<p><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_cartpole2/CartPole2.png" alt="cart_pole2"></p>
<h2 id="环境初始化"><a href="#环境初始化" class="headerlink" title="环境初始化"></a>环境初始化</h2><p>环境初始化主要包含创建isaacgym仿真器实例，设置相关缓存，导入智能体模型与配置，创建模型实例与获取相关状态矩阵，创建地面，初始化奖励函数等(略过了一些不太重要的步骤，完整步骤参见代码)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cfg: Cartpole2Config, sim_params, physics_engine, sim_device, headless</span>):</span><br><span class="line">        self.cfg = cfg  <span class="comment"># 主要配置文件</span></span><br><span class="line">        self.sim_params = sim_params  <span class="comment"># 仿真参数配置</span></span><br><span class="line">        self.init_done = <span class="literal">False</span>  <span class="comment"># 是否初始化完成</span></span><br><span class="line">        self._parse_cfg(self.cfg)  <span class="comment"># 解析配置文件</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__(self.cfg, sim_params, physics_engine, sim_device, headless)</span><br><span class="line">        <span class="comment"># 初始化父类，和C++不一样，父类的初始化不一定在最开始</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.headless:  <span class="comment"># 设置渲染窗口的相机初始化位置</span></span><br><span class="line">            self.set_camera(self.cfg.viewer.pos, self.cfg.viewer.lookat)</span><br><span class="line">        self._init_buffers()  <span class="comment"># 初始化pytorch的buffer</span></span><br><span class="line">        self._prepare_reward_function()  <span class="comment"># 准备奖励函数</span></span><br><span class="line">        self.init_done = <span class="literal">True</span>  <span class="comment"># 初始化完成</span></span><br></pre></td></tr></table></figure>

<p>在父类构造函数中调用了<code>create_sim()</code>函数，在其中创建了仿真器实例，地面和创建了智能体。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_sim</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Creates simulation, terrain and evironments&quot;&quot;&quot;</span></span><br><span class="line">    self.sim = self.gym.create_sim(</span><br><span class="line">        self.sim_device_id,</span><br><span class="line">        self.graphics_device_id,</span><br><span class="line">        self.physics_engine,</span><br><span class="line">        self.sim_params,</span><br><span class="line">    )  <span class="comment"># 创建仿真器handle</span></span><br><span class="line">    self._create_ground_plane()  <span class="comment"># 创建地面</span></span><br><span class="line">    self._create_envs()  <span class="comment"># 创建智能体</span></span><br></pre></td></tr></table></figure>

<p>我们重点关注一下<code>_create_envs()</code>这个函数，这个函数首先从<code>cartpole_config.asset.file</code>中读取了urdf文件并将其导入。导入时配置了一系列选项。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">asset_path = self.cfg.asset.file.<span class="built_in">format</span>(LEGGED_GYM_ROOT_DIR=LEGGED_GYM_ROOT_DIR)</span><br><span class="line">asset_root = os.path.dirname(asset_path)</span><br><span class="line">asset_file = os.path.basename(asset_path)  <span class="comment"># 设置URDF文件名和文件路径</span></span><br><span class="line">asset_options = gymapi.AssetOptions()  <span class="comment"># 设置机器人模型的各种属性</span></span><br><span class="line"><span class="comment"># 属性的具体含义可以参考isaacgym的文档</span></span><br><span class="line"><span class="comment"># https://blog.zzshub.cn/legged_gym/api/python/struct_py.html#isaacgym.gymapi.AssetOptions</span></span><br><span class="line"><span class="comment">#...</span></span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">robot_asset = self.gym.load_asset(self.sim, asset_root, asset_file, asset_options)</span><br></pre></td></tr></table></figure>

<p>之后在一个循环中创建了环境实例，并对每个实例修改了关节驱动模式的参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">start_pose = gymapi.Transform()</span><br><span class="line">start_pose.p = gymapi.Vec3(<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.5</span>)  <span class="comment"># 设置机器人初始位置</span></span><br><span class="line">env_lower = gymapi.Vec3(<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>)</span><br><span class="line">env_upper = gymapi.Vec3(self.cfg.env.env_spacing, self.cfg.env.env_spacing, <span class="number">0.0</span>)  <span class="comment"># 设置环境边界</span></span><br><span class="line">self.actor_handles = []</span><br><span class="line">self.envs = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_envs):</span><br><span class="line">    <span class="comment"># 创建环境</span></span><br><span class="line">    env_handle = self.gym.create_env(self.sim, env_lower, env_upper, <span class="built_in">int</span>(np.sqrt(selfnum_envs)))</span><br><span class="line">    <span class="comment"># 在环境中创建机器人实例</span></span><br><span class="line">    actor_handle = self.gym.create_actor(</span><br><span class="line">        env_handle,</span><br><span class="line">        robot_asset,</span><br><span class="line">        start_pose,</span><br><span class="line">        self.cfg.asset.name,</span><br><span class="line">        i,</span><br><span class="line">        self.cfg.asset.self_collisions,</span><br><span class="line">        <span class="number">0</span>,</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 设置关节驱动模式</span></span><br><span class="line">    dof_props = self.gym.get_actor_dof_properties(env_handle, actor_handle)  <span class="comment"># 获取关节属性</span></span><br><span class="line">    dof_props[<span class="string">&quot;driveMode&quot;</span>][<span class="number">0</span>] = gymapi.DOF_MODE_EFFORT  <span class="comment"># 设置1关节(小车关节)驱动模式为力矩驱动</span></span><br><span class="line">    dof_props[<span class="string">&quot;driveMode&quot;</span>][<span class="number">1</span>] = gymapi.DOF_MODE_NONE  <span class="comment"># 设置2关节(杆1关节)驱动模式为无驱动</span></span><br><span class="line">    dof_props[<span class="string">&quot;driveMode&quot;</span>][<span class="number">2</span>] = gymapi.DOF_MODE_NONE  <span class="comment"># 设置3关节(杆2关节)驱动模式为无驱动</span></span><br><span class="line">    dof_props[<span class="string">&quot;stiffness&quot;</span>][:] = <span class="number">0.0</span></span><br><span class="line">    dof_props[<span class="string">&quot;damping&quot;</span>][:] = <span class="number">0.0</span>  <span class="comment"># 设置关节pd为0</span></span><br><span class="line">    self.gym.set_actor_dof_properties(env_handle, actor_handle, dof_props)  <span class="comment"># 设置关节属性</span></span><br><span class="line">    self.envs.append(env_handle)  <span class="comment"># 记录环境handle</span></span><br><span class="line">    self.actor_handles.append(actor_handle)  <span class="comment"># 记录机器人实例handle</span></span><br></pre></td></tr></table></figure>

<p>此外我们再关注一下<code>_init_buffers()</code>这个函数，该函数在创建缓存之外还从isaacgym仿真器中获取到了保存倒立摆智能体关节角信息的相关矩阵，并将其转换为了pytorch张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dof_state_tensor = self.gym.acquire_dof_state_tensor(self.sim)  <span class="comment"># 从仿真器获取关节状态的矩阵</span></span><br><span class="line">self.gym.refresh_dof_state_tensor(self.sim)  <span class="comment"># 刷新关节状态</span></span><br><span class="line"><span class="comment"># create some wrapper tensors for different slices</span></span><br><span class="line">self.dof_state = gymtorch.wrap_tensor(dof_state_tensor)  <span class="comment"># 将关节状态矩阵包装成pytorch tensor</span></span><br><span class="line">self.dof_pos = self.dof_state.view(self.num_envs, self.num_dof, <span class="number">2</span>)[..., <span class="number">0</span>]</span><br><span class="line">self.dof_vel = self.dof_state.view(self.num_envs, self.num_dof, <span class="number">2</span>)[..., <span class="number">1</span>]  <span class="comment"># 将关节状态矩阵分位置和速度两部分</span></span><br></pre></td></tr></table></figure>

<h2 id="观测与奖励"><a href="#观测与奖励" class="headerlink" title="观测与奖励"></a>观测与奖励</h2><p>二阶倒立摆环境的观测包括各个关节角的速度和位置，是一个6维向量。观测时刷新isaacgym仿真器中的关节角状态，之后将其输入到观测矩阵中。其中观测量的维度在<code>cartpole2_config.py</code>中的<code>Cartpole2Config.env.num_observations</code>定义。注意计算观测值前需要将关节角状态矩阵刷新，计算观测值最后需要对观测值限幅。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用 compute_observation()前：</span></span><br><span class="line">self.gym.refresh_dof_state_tensor(self.sim)  <span class="comment">#刷新关节角信息</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_observations</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Computes observations&quot;&quot;&quot;</span></span><br><span class="line">    self.obs_buf = torch.cat(</span><br><span class="line">        (</span><br><span class="line">            (self.dof_pos - self.default_dof_pos) * self.obs_scales.dof_pos,  <span class="comment"># 关节位置</span></span><br><span class="line">            self.dof_vel * self.obs_scales.dof_vel,  <span class="comment"># 关节速度</span></span><br><span class="line">        ),</span><br><span class="line">        dim=-<span class="number">1</span>,</span><br><span class="line">    )</span><br><span class="line"><span class="comment"># 调用compute_observation()后：</span></span><br><span class="line">    clip_obs = self.cfg.normalization.clip_observations</span><br><span class="line">    self.obs_buf = torch.clip(self.obs_buf, -clip_obs, clip_obs)  <span class="comment"># 对观测进行裁剪，防止过大或过小</span></span><br><span class="line">        </span><br></pre></td></tr></table></figure>

<p>奖励函数是强化学习算法中的核心，在实验中奖励函数定义为如下：<br>$$<br>r_t&#x3D;(AngleScale\cdot(PoleAngle^2+PoleAngle2^2)+ VelScale\cdot(|CartVel|+|PoleVel|+|Pole2Vel|)+TerminationReward)\cdot dt<br>$$<br>其中 $AngleScale$，$VelScale$定义在<code>cartpole2_config.py</code>中的<code>Cartpole2Config.rewards.scales</code>中，均为负值，$dt$为仿真的最小时间片长度在这里定义为<code>Cartpole2Config.sim.dt</code>*<code>Cartpole2Config.control.decimation</code>。该函数的含义为关节角速度越小，关节角越接近0点(即竖直状态)，那么奖励越大，且倒立摆倒下时还需要被惩罚。</p>
<p>奖励函数的定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_reward_joint_angle</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 设置关节角度奖励，这里是一个简单的奖励函数，</span></span><br><span class="line">        <span class="comment"># 奖励为关节角度的平方，这里的奖励为正，但是乘上scales后为负，</span></span><br><span class="line">        <span class="comment"># 关节角度越大，奖励越小</span></span><br><span class="line">        pole_angle = self.dof_pos[:, <span class="number">1</span>]</span><br><span class="line">        pole_angle2 = self.dof_pos[:, <span class="number">2</span>]</span><br><span class="line">        reward = pole_angle * pole_angle + pole_angle2 * pole_angle2 * <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> reward</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_reward_joint_velocity</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 设置关节速度奖励，这里是一个简单的奖励函数，</span></span><br><span class="line">        <span class="comment"># 奖励为关节速度的平方，这里的奖励为正，但是乘上scales后为负，</span></span><br><span class="line">        <span class="comment"># 关节速度越大，奖励越小，限制关节速度的大小</span></span><br><span class="line">        cart_vel = self.dof_vel[:, <span class="number">0</span>]</span><br><span class="line">        pole_vel = self.dof_vel[:, <span class="number">1</span>]</span><br><span class="line">        pole_vel2 = self.dof_vel[:, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        reward = torch.<span class="built_in">abs</span>(cart_vel) + torch.<span class="built_in">abs</span>(pole_vel) + torch.<span class="built_in">abs</span>(pole_vel2)</span><br><span class="line">        <span class="keyword">return</span> reward</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_reward_termination</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 设置终止奖励，当倒立摆倒下的时候需要给一点惩罚</span></span><br><span class="line">        cart_pos = self.dof_pos[:, <span class="number">0</span>]</span><br><span class="line">        pole_angle = self.dof_pos[:, <span class="number">1</span>]</span><br><span class="line">        pole_angle2 = self.dof_pos[:, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        reward = torch.zeros(self.num_envs, dtype=torch.<span class="built_in">float</span>, device=self.device)</span><br><span class="line">        reward = torch.where(torch.<span class="built_in">abs</span>(cart_pos) &gt; <span class="number">3</span>, torch.ones_like(reward) * -<span class="number">2.0</span>, reward)</span><br><span class="line">        reward = torch.where(torch.<span class="built_in">abs</span>(pole_angle) &gt; torch.pi / <span class="number">2</span>, torch.ones_like(reward) * -<span class="number">2.0</span>, reward)</span><br><span class="line">        reward = torch.where(torch.<span class="built_in">abs</span>(pole_angle2) &gt; torch.pi / <span class="number">2</span>, torch.ones_like(reward) * -<span class="number">2.0</span>, reward)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> reward</span><br></pre></td></tr></table></figure>

<p>这些奖励函数由<code>_prepare_reward_function()</code>函数在环境初始化时初始化，和由<code>self.compute_reward()</code>函数在每个step中调用并计算奖励。这两个函数在本入门教程中就不细讲了，建议读者自行阅读源代码理解。</p>
<h2 id="编写复位函数"><a href="#编写复位函数" class="headerlink" title="编写复位函数"></a>编写复位函数</h2><p>复位函数的作用在于单个环境中的智能体训练超过一定时间后或当其陷入不可挽回的状态后及时复位防止收集到过多无效状态影响训练效果。复位函数主要包括根据条件找出需要复位的智能体以及复位该智能体对应的环境。</p>
<p>找出待复位的环境定义在<code>check_termination()</code>函数中，主要根据关节角度和训练时间来判断是否需要复位，并将结果记录在&#96;&#96;&#96;reset_buf&#96;&#96;变量中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">check_termination</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Check if environments need to be reset&quot;&quot;&quot;</span></span><br><span class="line">        self.reset_buf = torch.zeros_like(self.episode_length_buf)  <span class="comment"># 重置buffer</span></span><br><span class="line">        self.time_out_buf = self.episode_length_buf &gt; self.max_episode_length</span><br><span class="line">        self.reset_buf |= self.time_out_buf  <span class="comment"># 如果超过最大episode长度，需要重置</span></span><br><span class="line"></span><br><span class="line">        cart_pos = self.dof_pos[:, <span class="number">0</span>]  <span class="comment"># 获取小车位置</span></span><br><span class="line">        pole_angle = self.dof_pos[:, <span class="number">1</span>]  <span class="comment"># 获取杆1角度</span></span><br><span class="line">        pole_angle2 = self.dof_pos[:, <span class="number">2</span>]  <span class="comment"># 获取杆2角度</span></span><br><span class="line">        self.reset_buf |= torch.<span class="built_in">abs</span>(cart_pos) &gt; <span class="number">3.0</span>  <span class="comment"># 如果小车位置超过3，需要重置</span></span><br><span class="line">        self.reset_buf |= torch.<span class="built_in">abs</span>(pole_angle) &gt; torch.pi / <span class="number">2</span>  <span class="comment"># 如果杆1角度超过90度，需要重置</span></span><br><span class="line">        self.reset_buf |= torch.<span class="built_in">abs</span>(pole_angle2) &gt; torch.pi / <span class="number">2</span>  <span class="comment"># 如果杆2角度超过90度，需要重置</span></span><br></pre></td></tr></table></figure>

<p>实际执行复位的函数为<code>reset_idx()</code>，该函数将重置关节角，重置训练时长，以及记录一下当前训练片段的累计奖励等。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">reset_idx</span>(<span class="params">self, env_ids</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(env_ids) == <span class="number">0</span>:  <span class="comment"># 如果没有需要重置的环境，直接返回</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># reset robot states</span></span><br><span class="line">    self._reset_dofs(env_ids)  <span class="comment"># 重置关节位置和速度</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># reset buffers</span></span><br><span class="line">    self.episode_length_buf[env_ids] = <span class="number">0</span>  <span class="comment"># 重置episode长度</span></span><br><span class="line">    self.reset_buf[env_ids] = <span class="number">1</span>  <span class="comment"># 设置buffer，后续policy需要知道哪些环境被重置了</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># fill extras，记录一些奖励相关的信息，供log使用</span></span><br><span class="line">    self.extras[<span class="string">&quot;episode&quot;</span>] = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> self.episode_sums.keys():</span><br><span class="line">        self.extras[<span class="string">&quot;episode&quot;</span>][<span class="string">&quot;rew_&quot;</span> + key] = (</span><br><span class="line">            torch.mean(self.episode_sums[key][env_ids]) / self.max_episode_length_s</span><br><span class="line">        )</span><br><span class="line">        self.episode_sums[key][env_ids] = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># send timeout info to the algorithm</span></span><br><span class="line">    <span class="keyword">if</span> self.cfg.env.send_timeouts:</span><br><span class="line">        self.extras[<span class="string">&quot;time_outs&quot;</span>] = self.time_out_buf</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_reset_dofs</span>(<span class="params">self, env_ids</span>):</span><br><span class="line">    positions = <span class="number">0.2</span> * (torch.rand((<span class="built_in">len</span>(env_ids), self.num_dof), device=self.device) - <span class="number">0.5</span>)</span><br><span class="line">    velocities = <span class="number">0.5</span> * (torch.rand((<span class="built_in">len</span>(env_ids), self.num_dof), device=self.device) - <span class="number">0.5</span>)</span><br><span class="line">    self.dof_pos[env_ids, :] = positions[:]</span><br><span class="line">    self.dof_vel[env_ids, :] = velocities[:]  <span class="comment"># 复位时随机指定位置和速度</span></span><br><span class="line"></span><br><span class="line">    env_ids_int32 = env_ids.to(dtype=torch.int32)</span><br><span class="line">    self.gym.set_dof_state_tensor_indexed(</span><br><span class="line">        self.sim,</span><br><span class="line">        gymtorch.unwrap_tensor(self.dof_state),</span><br><span class="line">        gymtorch.unwrap_tensor(env_ids_int32),</span><br><span class="line">        <span class="built_in">len</span>(env_ids_int32),</span><br><span class="line">    )  <span class="comment"># 将新关节位置应用到仿真中</span></span><br></pre></td></tr></table></figure>

<h2 id="编写step函数"><a href="#编写step函数" class="headerlink" title="编写step函数"></a>编写step函数</h2><p>step函数是强化学习环境中的核心函数，在每一步迭代中都会调用。如前文的基本概念所述，环境需要做的就是接收动作策略的输入，并提供相应的下一时刻的输出，和这一步策略所获得的奖励。由此可以得出step函数的编写主要流程。<br>(1) 该函数首先接受由策略提供的action，并计算出对应的torque;<br>(2) 然后将torque应用到仿真中，进行一次仿真;<br>(3) 仿真完成后，调用post_physics_step()函数，检查终止条件，计算奖励，更新观测等。<br>(4) 最后返回观测，奖励，终止标志等信息。强化学习仿真环境的编写主要过程包括：应用action，仿真，计算奖励，检查终止条件，更新观测，返回信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self, actions</span>):</span><br><span class="line">        clip_actions = self.cfg.normalization.clip_actions  <span class="comment"># action的范围</span></span><br><span class="line">        self.actions = torch.clip(actions, -clip_actions, clip_actions).to(self.device)</span><br><span class="line">        <span class="comment"># 限制action的范围，防止过大或过小</span></span><br><span class="line">        <span class="comment"># step physics and render each frame</span></span><br><span class="line">        self.render()  <span class="comment"># 渲染</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.cfg.control.decimation):</span><br><span class="line">            <span class="comment"># 计算torque，将其应用在关节上，并进行一次仿真，decimation是控制频率的参数</span></span><br><span class="line">            self.torques = self._compute_torques(self.actions).view(self.torques.shape)  <span class="comment"># 计算torque</span></span><br><span class="line">            self.gym.set_dof_actuation_force_tensor(</span><br><span class="line">                self.sim, gymtorch.unwrap_tensor(self.torques)</span><br><span class="line">            )  <span class="comment"># 将torque应用到仿真中</span></span><br><span class="line">            self.gym.simulate(self.sim)  <span class="comment"># 进行一次仿真</span></span><br><span class="line">            <span class="keyword">if</span> self.device == <span class="string">&quot;cpu&quot;</span>:</span><br><span class="line">                self.gym.fetch_results(self.sim, <span class="literal">True</span>)</span><br><span class="line">            self.gym.refresh_dof_state_tensor(self.sim)  <span class="comment"># 刷新关节状态</span></span><br><span class="line"></span><br><span class="line">        self.post_physics_step()  <span class="comment"># 检查终止条件，计算奖励，更新观测等</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># return clipped obs, clipped states (None), rewards, dones and infos</span></span><br><span class="line">        clip_obs = self.cfg.normalization.clip_observations</span><br><span class="line">        self.obs_buf = torch.clip(self.obs_buf, -clip_obs, clip_obs)  <span class="comment"># 对观测进行裁剪，防止过大或过小</span></span><br><span class="line">        <span class="keyword">if</span> self.privileged_obs_buf <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  <span class="comment"># 本实验中没有使用到特权观测信息</span></span><br><span class="line">            self.privileged_obs_buf = torch.clip(self.privileged_obs_buf, -clip_obs, clip_obs)</span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            self.obs_buf,</span><br><span class="line">            self.privileged_obs_buf,</span><br><span class="line">            self.rew_buf,</span><br><span class="line">            self.reset_buf,</span><br><span class="line">            self.extras,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">post_physics_step</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;check terminations, compute observations and rewards</span></span><br><span class="line"><span class="string">        calls self._post_physics_step_callback() for common computations</span></span><br><span class="line"><span class="string">        calls self._draw_debug_vis() if needed</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># in some cases a simulation step might be required to refresh some obs (for example body positions)</span></span><br><span class="line">        self.gym.refresh_dof_state_tensor(self.sim)  <span class="comment"># 刷新关节状态</span></span><br><span class="line"></span><br><span class="line">        self.episode_length_buf += <span class="number">1</span>  <span class="comment"># 记录每个episode的长度</span></span><br><span class="line">        self.common_step_counter += <span class="number">1</span>  <span class="comment"># 记录总的步数</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute observations, rewards, resets, ...</span></span><br><span class="line">        self.check_termination()  <span class="comment"># 检查是否需要终止</span></span><br><span class="line">        self.compute_reward()  <span class="comment"># 计算奖励</span></span><br><span class="line">        env_ids = self.reset_buf.nonzero(as_tuple=<span class="literal">False</span>).flatten()  <span class="comment"># 从reset buffer中找到需要重置的环境的id</span></span><br><span class="line">        self.reset_idx(env_ids)  <span class="comment"># 重置一些环境</span></span><br><span class="line">        self.compute_observations()  <span class="comment"># 计算观测</span></span><br></pre></td></tr></table></figure>

<p>以上就是二阶倒立摆环境的大致内容，<strong>值得注意的是该环境的奖励函数编写的并不够充分，并不能实现完美的平衡效果</strong>，各位读者可以自行尝试更改奖励函数的形式或者权重参数来获得更好的效果。</p>
<hr>
<p>EOF</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.zzshub.cn">Zishun Zhou</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.zzshub.cn/2024/06/25/DRL_LeggedgymCartpole2/">https://blog.zzshub.cn/2024/06/25/DRL_LeggedgymCartpole2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.zzshub.cn" target="_blank">ZZSHUB</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/">机器人</a></div><div class="post_share"><div class="social-share" data-image="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_cartpole2/cover.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/wechatpay.JPG" target="_blank"><img class="post-qr-code-img" src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/wechatpay.JPG" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/06/21/DRL_LeggedgymInstall/" title="强化学习仿真器Isaac Gym的安装，配置，与初步使用"><img class="cover" src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_installIsaacgym/cover.png" onerror="onerror=null;src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">强化学习仿真器Isaac Gym的安装，配置，与初步使用</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/06/21/DRL_LeggedgymInstall/" title="强化学习仿真器Isaac Gym的安装，配置，与初步使用"><img class="cover" src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_installIsaacgym/cover.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-21</div><div class="title">强化学习仿真器Isaac Gym的安装，配置，与初步使用</div></div></a></div><div><a href="/2024/05/21/start_rl/" title="机器人控制中的强化学习极简入门指南"><img class="cover" src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/start_rl/cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-21</div><div class="title">机器人控制中的强化学习极简入门指南</div></div></a></div><div><a href="/2023/07/26/DRL_RaisimGymTorch/" title="强化学习仿真器Raisim进行深度强化学习的初步尝试"><img class="cover" src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/RaisimInstall/logo.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-26</div><div class="title">强化学习仿真器Raisim进行深度强化学习的初步尝试</div></div></a></div><div><a href="/2023/07/26/DRL_RaisimInstall/" title="强化学习仿真器Raisim的安装，配置，与初步使用"><img class="cover" src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/RaisimInstall/logo.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-26</div><div class="title">强化学习仿真器Raisim的安装，配置，与初步使用</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/zzslogo.jpg" onerror="this.onerror=null;this.src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.gif'" alt="avatar"/></div><div class="author-info__name">Zishun Zhou</div><div class="author-info__description">周子顺</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">42</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ZzzzzzS"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ZzzzzzS" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:zhouzishun@mail.zzshub.cn" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fas fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">这个人很懒，他什么也没留下</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%BF%E7%9C%9F%E7%8E%AF%E5%A2%83Legged-Gym%E7%9A%84%E5%88%9D%E6%AD%A5%E4%BD%BF%E7%94%A8%E2%80%94%E2%80%94%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%E4%BA%8C%E9%98%B6%E5%80%92%E7%AB%8B%E6%91%86"><span class="toc-number">1.</span> <span class="toc-text">强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9E%E9%A1%BE%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-%E2%80%94%E2%80%93-%E4%BA%94%E5%85%83%E7%BB%84"><span class="toc-number">2.</span> <span class="toc-text">回顾强化学习基本概念 —– 五元组</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Legged-Gym-ver-ZZS-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85"><span class="toc-number">3.</span> <span class="toc-text">Legged Gym(ver. ZZS) 环境安装</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Legged-Gym-ver-ZZS-%E7%8E%AF%E5%A2%83%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84%E4%BB%8B%E7%BB%8D"><span class="toc-number">4.</span> <span class="toc-text">Legged Gym(ver. ZZS) 环境基本结构介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%E6%A2%B3%E7%90%86"><span class="toc-number">4.1.</span> <span class="toc-text">代码文件结构梳理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95"><span class="toc-number">4.2.</span> <span class="toc-text">训练与测试</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E4%B8%8E%E9%85%8D%E7%BD%AE%E7%AE%80%E4%BB%8B"><span class="toc-number">4.3.</span> <span class="toc-text">环境与配置简介</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E7%AC%AC%E4%B8%80%E6%AD%A5-%E2%80%94%E2%80%94-%E4%BA%8C%E9%98%B6%E5%80%92%E7%AB%8B%E6%91%86%E8%AE%AD%E7%BB%83"><span class="toc-number">5.</span> <span class="toc-text">强化学习实践第一步 —— 二阶倒立摆训练</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">5.1.</span> <span class="toc-text">环境初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%82%E6%B5%8B%E4%B8%8E%E5%A5%96%E5%8A%B1"><span class="toc-number">5.2.</span> <span class="toc-text">观测与奖励</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E5%A4%8D%E4%BD%8D%E5%87%BD%E6%95%B0"><span class="toc-number">5.3.</span> <span class="toc-text">编写复位函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%96%E5%86%99step%E5%87%BD%E6%95%B0"><span class="toc-number">5.4.</span> <span class="toc-text">编写step函数</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/06/25/DRL_LeggedgymCartpole2/" title="强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_cartpole2/cover.jpg" onerror="this.onerror=null;this.src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.jpg'" alt="强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆"/></a><div class="content"><a class="title" href="/2024/06/25/DRL_LeggedgymCartpole2/" title="强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆">强化学习仿真环境Legged Gym的初步使用——训练一个二阶倒立摆</a><time datetime="2024-06-25T04:00:00.000Z" title="发表于 2024-06-25 12:00:00">2024-06-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/06/21/DRL_LeggedgymInstall/" title="强化学习仿真器Isaac Gym的安装，配置，与初步使用"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/DRL_installIsaacgym/cover.png" onerror="this.onerror=null;this.src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.jpg'" alt="强化学习仿真器Isaac Gym的安装，配置，与初步使用"/></a><div class="content"><a class="title" href="/2024/06/21/DRL_LeggedgymInstall/" title="强化学习仿真器Isaac Gym的安装，配置，与初步使用">强化学习仿真器Isaac Gym的安装，配置，与初步使用</a><time datetime="2024-06-21T04:00:00.000Z" title="发表于 2024-06-21 12:00:00">2024-06-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/21/start_rl/" title="机器人控制中的强化学习极简入门指南"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/start_rl/cover.jpg" onerror="this.onerror=null;this.src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.jpg'" alt="机器人控制中的强化学习极简入门指南"/></a><div class="content"><a class="title" href="/2024/05/21/start_rl/" title="机器人控制中的强化学习极简入门指南">机器人控制中的强化学习极简入门指南</a><time datetime="2024-05-21T04:00:00.000Z" title="发表于 2024-05-21 12:00:00">2024-05-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/08/30/wslgperformace/" title="WSL中的GPU原理总结"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/wslgpuperformance/logo.png" onerror="this.onerror=null;this.src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.jpg'" alt="WSL中的GPU原理总结"/></a><div class="content"><a class="title" href="/2023/08/30/wslgperformace/" title="WSL中的GPU原理总结">WSL中的GPU原理总结</a><time datetime="2023-08-30T06:12:32.000Z" title="发表于 2023-08-30 14:12:32">2023-08-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/26/DRL_RaisimGymTorch/" title="强化学习仿真器Raisim进行深度强化学习的初步尝试"><img src="https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/RaisimInstall/logo.png" onerror="this.onerror=null;this.src='https://zzshubimage-1253829354.cos.ap-beijing.myqcloud.com/blog/404.jpg'" alt="强化学习仿真器Raisim进行深度强化学习的初步尝试"/></a><div class="content"><a class="title" href="/2023/07/26/DRL_RaisimGymTorch/" title="强化学习仿真器Raisim进行深度强化学习的初步尝试">强化学习仿真器Raisim进行深度强化学习的初步尝试</a><time datetime="2023-07-26T08:12:32.000Z" title="发表于 2023-07-26 16:12:32">2023-07-26</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2017 - 2024 By Zishun Zhou</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">喵喵喵喵喵</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/utils.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/main.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/tw_cn.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const initGitalk = () => {
    const gitalk = new Gitalk(Object.assign({
      clientID: 'Ov23li0kkKyhMGCSCF8C',
      clientSecret: 'e6803156ae2eb0273961046aaa938b39152eb81a',
      repo: 'ZzzzzzS.github.io',
      owner: 'ZzzzzzS',
      admin: ['ZzzzzzS'],
      id: '7aae5966c277d719132d909912cbca0b',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async() => {
    if (typeof Gitalk === 'function') initGitalk()
    else {
      await getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk()
    }
  }
  
  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/search/local-search.min.js"></script></div></div><script src="https://cdn.jsdelivr.net/npm/live2d-widget@^3.1.3/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"https://cdn.jsdelivr.net/npm/live2d-widget-model-shizuku/assets/shizuku.model.json"},"display":{"position":"left","hOffset":60,"vOffset":0,"width":150,"height":300},"mobile":{"show":false},"react":{"opacity":1},"dialog":{"enable":true,"hitokoto":true},"log":false});</script></body></html>